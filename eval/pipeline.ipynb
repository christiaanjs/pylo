{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational simulation study\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import json\n",
    "import pickle\n",
    "import newick\n",
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import templating\n",
    "import variational_analysis\n",
    "import topology_inference\n",
    "import subprocess\n",
    "import process_results\n",
    "import util\n",
    "import Bio\n",
    "import Bio.Phylo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "with open('config.yaml') as f:\n",
    "    config = yaml.load(f)\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.do_seeding(config)\n",
    "out_dir = config['out_dir']\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "build_templates = templating.TemplateBuilder(out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_size_prior = scipy.stats.lognorm(scale=np.exp(config['prior_params']['pop_size']['m']), s=config['prior_params']['pop_size']['s'])\n",
    "xs = np.arange(0, pop_size_prior.ppf(0.999), 0.001)\n",
    "plt.plot(xs, pop_size_prior.pdf(xs))\n",
    "pop_size_prior.ppf([0.025, 0.975])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beast_args = ['java'] + util.cmd_kwargs(jar=config['beast_jar'], seed=config['seed']) + ['-overwrite']\n",
    "pop_size, taxon_names, date_trait_string = build_templates.build_tree_sim(config)\n",
    "pop_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels\n",
    "date_trait_dict = topology_inference.parse_date_trait_string(date_trait_string)\n",
    "sampling_times = list(date_trait_dict.values())\n",
    "plt.scatter(sampling_times, np.zeros_like(sampling_times), alpha=0.5);\n",
    "np.max(sampling_times) - np.min(sampling_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "def run_beast(xml_path, **kwargs):\n",
    "    result = subprocess.run(beast_args + [xml_path], **kwargs)\n",
    "    if result.returncode != 0:\n",
    "        print(result.stderr)\n",
    "        print(result.stdout)\n",
    "        raise RuntimeError('BEAST run failed')\n",
    "    else:\n",
    "        print('Ran BEAST ({0}) successfully'.format(xml_path))\n",
    "    \n",
    "\n",
    "run_beast(build_templates.tree_sim_out_path)\n",
    "newick_string = build_templates.extract_newick_string(build_templates.tree_sim_result_path)\n",
    "bio_tree = next(Bio.Phylo.parse(StringIO(newick_string), 'newick'))\n",
    "Bio.Phylo.draw(bio_tree)\n",
    "tree_height = max(bio_tree.depths().values())\n",
    "tree_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newick_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_summary = {\n",
    "    'config': config,\n",
    "    'pop_size': pop_size,\n",
    "    'date_trait_string': date_trait_string,\n",
    "    'newick_string': newick_string\n",
    "}\n",
    "\n",
    "with(open(build_templates.run_summary_path, 'w')) as f:\n",
    "    yaml.dump(run_summary, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "build_templates.build_seq_sim(config, taxon_names, newick_string)\n",
    "run_beast(build_templates.seq_sim_out_path)\n",
    "sequence_dict = build_templates.extract_sequence_dict()\n",
    "sequence_values = [pd.Series(list(x)) for x in sequence_dict.values()]\n",
    "char_counts = pd.concat(sequence_values).value_counts()\n",
    "char_counts / sum(char_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "prop_differences = [np.mean(x != y) for x, y in combinations(sequence_values, 2)]\n",
    "plt.hist(prop_differences);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neighbour joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nj_tree = topology_inference.get_neighbor_joining_tree(sequence_dict)\n",
    "Bio.Phylo.draw(nj_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rooting & dating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topology_inference.build_lsd_inputs(config, build_templates, nj_tree, date_trait_string)\n",
    "subprocess.run([config['lsd_executable']] + topology_inference.get_lsd_args(build_templates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsd_tree = topology_inference.extract_lsd_tree(build_templates)    \n",
    "analysis_newick_io = StringIO()\n",
    "Bio.Phylo.write([lsd_tree], analysis_newick_io, format='newick')\n",
    "analysis_newick = analysis_newick_io.getvalue()\n",
    "    \n",
    "fig, axs = plt.subplots(ncols=2, figsize=(20,10))\n",
    "Bio.Phylo.draw(bio_tree, axes=axs[0], do_show=False)\n",
    "axs[0].set_title('True tree')\n",
    "Bio.Phylo.draw(lsd_tree, show_confidence=False, axes=axs[1], do_show=False)\n",
    "axs[1].set_title('Estimated tree - Neighbour joining + LSD');\n",
    "analysis_newick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEAST analysis (estimating tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_templates.build_beast_analysis(util.update_dict(config, estimate_topology=True), analysis_newick, date_trait_string, sequence_dict)\n",
    "run_beast(build_templates.beast_analysis_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(build_templates.beast_analysis_tree_path) as f:\n",
    "    beast_trees = list(Bio.Phylo.parse(f, 'nexus'))\n",
    "    \n",
    "Bio.Phylo.draw(beast_trees[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beast_trace_df = process_results.process_beast_trace(build_templates.beast_analysis_trace_path, config, burn_in=False)\n",
    "beast_trace_df.plot(subplots=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Effective sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_values = {\n",
    "    'tree_height': tree_height,\n",
    "    'pop_size': pop_size,\n",
    "    'kappa': config['kappa']\n",
    "}\n",
    "\n",
    "p_limits = np.array([0.025, 0.975])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beast_quantiles(trace, ps):\n",
    "    return np.stack([np.quantile(trace.values[int(i * config['burn_in']):i], ps, axis=0) for i in range(1, trace.shape[0])])\n",
    "\n",
    "def plot_trace_hpd(quantiles, varnames, xs=None, plot_prior=False): # quantiles: iteration, p, var\n",
    "    n_vars = quantiles.shape[2]\n",
    "    if xs is None:\n",
    "        xs = np.arange(quantiles.shape[0])\n",
    "    fig, axs = plt.subplots(nrows=n_vars, figsize=(20, 20))\n",
    "    for j in range(n_vars):\n",
    "        ax = axs[j]\n",
    "        varname = varnames[j]\n",
    "        ax.set_ylabel(varname)\n",
    "        \n",
    "        ax.fill_between(xs, quantiles[:, 0, j], quantiles[:, 1, j], alpha=0.5, label='95% posterior interval')\n",
    "        \n",
    "        if plot_prior and varname in config['prior_params']:\n",
    "            prior = scipy.stats.lognorm(scale=np.exp(config['prior_params'][varname]['m']), s=config['prior_params'][varname]['s'])\n",
    "            ax.axhspan(*prior.ppf(p_limits), color='yellow', alpha=0.3, label='95% prior interval')\n",
    "        \n",
    "        ax.axhline(true_values[varname], color='green', label='True value')\n",
    "        \n",
    "        ax.legend()\n",
    "plot_trace_hpd(get_beast_quantiles(beast_trace_df, p_limits), beast_trace_df.columns, xs=np.arange(beast_trace_df.shape[0] - 1)*config['log_every'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEAST analysis (fixed tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beast_fixed_out_file = 'beast-analysis-fixed.xml'\n",
    "beast_fixed_trace_file = 'beast-log-fixed.log'\n",
    "beast_fixed_tree_file = 'beast-log-fixed.trees'\n",
    "\n",
    "build_templates.build_beast_analysis(util.update_dict(config, estimate_topology=False),\n",
    "                                     analysis_newick,\n",
    "                                     date_trait_string,\n",
    "                                     sequence_dict,\n",
    "                                     out_file=beast_fixed_out_file,\n",
    "                                     trace_file=beast_fixed_trace_file,\n",
    "                                     tree_file=beast_fixed_tree_file\n",
    "                                    )\n",
    "run_beast(build_templates.out_path / beast_fixed_out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beast_fixed_trace_df = process_results.process_beast_trace(build_templates.out_path / beast_fixed_trace_file, config, burn_in=False)\n",
    "beast_fixed_trace_df.plot(subplots=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trace_hpd(get_beast_quantiles(beast_fixed_trace_df, p_limits), beast_fixed_trace_df.columns, xs=np.arange(beast_fixed_trace_df.shape[0] - 1)*config['log_every'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational analysis (true tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = newick.loads(analysis_newick)[0]\n",
    "model = variational_analysis.construct_model(config, tree, sequence_dict)\n",
    "inference = variational_analysis.construct_inference(config, model)\n",
    "print(model.logp(model.test_point))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = pm.callbacks.Tracker(\n",
    "   mean=inference.approx.mean.eval,\n",
    "   std=inference.approx.std.eval\n",
    ")\n",
    "\n",
    "approx = inference.fit(config['n_iter'], callbacks=[tracker])\n",
    "\n",
    "with open(build_templates.pymc_analysis_result_path, 'wb') as f:\n",
    "    pickle.dump(tracker, f)\n",
    "\n",
    "plt.plot(approx.hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rvs_dict = { rv.name: rv for rv in model.deterministics }\n",
    "slices = { name: inference.approx.ordering.by_name[rv.transformed.name].slc for name, rv in rvs_dict.items() }\n",
    "indices_dict = { 'tree_height': slices['tree'].stop - 1, 'pop_size': slices['pop_size'].start, 'kappa': slices['kappa'].start  }\n",
    "\n",
    "means = np.stack(tracker.hist['mean'])\n",
    "stds = np.stack(tracker.hist['std'])\n",
    "\n",
    "varnames = list(indices_dict.keys())\n",
    "indices = np.array(list(indices_dict.values()))\n",
    "\n",
    "fig, axs = plt.subplots(ncols=len(tracker.hist), figsize=(20, 6))\n",
    "\n",
    "for ax, (name, param) in zip(axs, tracker.hist.items()):\n",
    "    ax.set_title(name)\n",
    "    vals = np.stack(param)\n",
    "    for varname, index in zip(varnames, indices):\n",
    "        ax.plot(vals[:, index], label=varname)\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylo.topology import TreeTopology\n",
    "topology = TreeTopology(tree)\n",
    "\n",
    "transformed_quantiles = scipy.stats.norm.ppf(p_limits[np.newaxis, :, np.newaxis],\n",
    "                                             loc=means[:, np.newaxis, indices],\n",
    "                                             scale=stds[:, np.newaxis, indices])\n",
    "\n",
    "transforms = {\n",
    "    'tree_height': lambda x: np.exp(x) + topology.get_max_leaf_height(),\n",
    "    'kappa': np.exp,\n",
    "    'pop_size': np.exp\n",
    "}\n",
    "\n",
    "quantiles = np.stack([transforms[varname](transformed_quantiles[:, :, i]) for i, varname in enumerate(varnames)], axis=-1)\n",
    "plot_trace_hpd(quantiles, varnames)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
